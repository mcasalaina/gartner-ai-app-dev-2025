{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Agent Simulator-Based Evaluation\n",
    "\n",
    "This notebook evaluates the Scheibmeir's restaurant agent using Azure AI Evaluation's simulator capabilities to generate contextually relevant test queries automatically.\n",
    "Instead of using pre-defined queries, it uses AI to simulate realistic customer interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
<<<<<<< HEAD
    "from dotenv import load_dotenv\n",
    "from azure.ai.evaluation.simulator import Simulator\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
=======
    "from typing import Dict, List, Optional, Any\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    AzureOpenAIModelConfiguration\n",
    ")\n",
    "from azure.ai.evaluation.simulator import Simulator\n",
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration from environment variables - using RESTAURANT settings only\n",
    "RESTAURANT_ASSISTANT_ID = os.getenv(\"RESTAURANT_ASSISTANT_ID\")\n",
    "RESTAURANT_ASSISTANT_MODEL = os.getenv(\"RESTAURANT_ASSISTANT_MODEL\")\n",
    "RESTAURANT_ASSISTANT_PROJECT = os.getenv(\"RESTAURANT_ASSISTANT_PROJECT\")\n",
    "\n",
    "print(f\"Restaurant Assistant ID: {RESTAURANT_ASSISTANT_ID}\")\n",
    "print(f\"Restaurant Assistant Model: {RESTAURANT_ASSISTANT_MODEL}\")\n",
    "print(f\"Restaurant Project: {RESTAURANT_ASSISTANT_PROJECT}\")"
=======
   "execution_count": null,\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Configuration from environment variables\n",
    "RESTAURANT_ASSISTANT_ID = os.getenv(\"RESTAURANT_ASSISTANT_ID\")\n",
    "RESTAURANT_ASSISTANT_PROJECT = os.getenv(\"RESTAURANT_ASSISTANT_PROJECT\")\n",
    "\n",
    "# Azure OpenAI configuration for evaluators and simulator\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"DEEP_RESEARCH_PROJECT_ENDPOINT\").replace(\"/api/projects/deep-research-demo-project\", \"\")\n",
    "AZURE_OPENAI_API_VERSION = \"2024-10-21\"\n",
    "AGENT_MODEL_DEPLOYMENT_NAME = os.getenv(\"AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Azure AI project configuration\n",
    "AZURE_SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_RESOURCE_GROUP_NAME = os.getenv(\"AZURE_RESOURCE_GROUP_NAME\")\n",
    "AZURE_PROJECT_NAME = os.getenv(\"AZURE_PROJECT_NAME\")\n",
    "\n",
    "print(f\"Restaurant Assistant ID: {RESTAURANT_ASSISTANT_ID}\")\n",
    "print(f\"Azure OpenAI Endpoint: {AZURE_OPENAI_ENDPOINT}\")\n",
    "print(f\"Model Deployment: {AGENT_MODEL_DEPLOYMENT_NAME}\")\n",
    "print(f\"Project: {AZURE_PROJECT_NAME}\")"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure credential and agents client\n",
    "credential = DefaultAzureCredential()\n",
=======
   "execution_count": null,\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "# Initialize Azure credential\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Initialize the Agents client\n",
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
    "agents_client = AgentsClient(\n",
    "    endpoint=RESTAURANT_ASSISTANT_PROJECT,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "print(\"Clients initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Define Target Function for Simulator\n",
    "\n",
    "This async function will be called by the simulator to test different scenarios."
=======
    "## Configure Model for Simulator and Evaluators"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_restaurant_agent_async(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Async function to query the restaurant agent.\n",
    "    Used by the simulator for dynamic testing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a thread and run with the agent\n",
=======
   "execution_count": null,\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Configure the model for AI-assisted evaluators and simulator\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AGENT_MODEL_DEPLOYMENT_NAME,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "print(\"Model configuration created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target Function for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,\n",
   "metadata": {},\n",
   "outputs": [],\n",
   "source": [
    "async def query_restaurant_agent_async(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Async function to query the restaurant agent and return the response.\n",
    "    This function will be used by the Azure AI evaluation framework.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a thread and run in one step\n",
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
    "        result = agents_client.create_thread_and_process_run(\n",
    "            agent_id=RESTAURANT_ASSISTANT_ID,\n",
    "            thread={\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": query\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if result.status.value == \"completed\":\n",
<<<<<<< HEAD
    "            # Get the agent's response\n",
    "            messages = agents_client.messages.list(thread_id=result.thread_id)\n",
    "            for msg in messages:\n",
    "                if msg.role.value == \"assistant\":\n",
=======
    "            # Get messages from the thread\n",
    "            messages = agents_client.messages.list(thread_id=result.thread_id)\n",
    "            \n",
    "            # Find the agent's response\n",
    "            for msg in messages:\n",
    "                if msg.role.value == \"agent\":\n",
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
    "                    return {\n",
    "                        \"response\": msg.content[0].text.value,\n",
    "                        \"query\": query\n",
    "                    }\n",
    "        \n",
    "        return {\n",
    "            \"response\": f\"Agent run failed with status: {result.status.value}\",\n",
    "            \"query\": query\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"response\": f\"Error querying agent: {str(e)}\",\n",
    "            \"query\": query\n",
    "        }\n",
    "\n",
<<<<<<< HEAD
    "# Test the function\n",
    "test_result = await query_restaurant_agent_async(\"What are the hours for Scheibmeir's?\")\n",
    "print(\"Test query result:\")\n",
    "print(f\"Query: {test_result['query']}\")\n",
    "print(f\"Response: {test_result['response'][:100]}...\")"
=======
    "print(\"Restaurant agent target function defined!\")"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Simulate Customer Scenarios\n",
    "\n",
    "Note: For this demo, we'll create manual simulation scenarios instead of using the full Azure AI Simulator which requires additional configuration."
=======
   "metadata": {},\n",
   "source": [
    "## Initialize Simulator"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different customer personas and scenarios\n",
    "simulation_scenarios = [\n",
    "    {\n",
    "        \"persona\": \"First-time customer\",\n",
    "        \"queries\": [\n",
    "            \"What type of restaurant is Scheibmeir's?\",\n",
    "            \"What are your most popular dishes?\",\n",
    "            \"Do you take reservations?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"persona\": \"Dietary restrictions customer\", \n",
    "        \"queries\": [\n",
    "            \"Do you have vegetarian options?\",\n",
    "            \"What gluten-free dishes do you offer?\",\n",
    "            \"Can you accommodate food allergies?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"persona\": \"Location-focused customer\",\n",
    "        \"queries\": [\n",
    "            \"Where is Scheibmeir's located?\",\n",
    "            \"What are your hours?\",\n",
    "            \"Is there parking available?\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"persona\": \"Price-conscious customer\",\n",
    "        \"queries\": [\n",
    "            \"What are your prices like?\",\n",
    "            \"Do you have any specials?\",\n",
    "            \"What's the average cost for dinner?\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(simulation_scenarios)} customer personas with simulation scenarios\")"
=======
   "execution_count": null,\n",
   "metadata": {},\n",
   "outputs": [],\n",
    "source": [
    "# Initialize the simulator\n",
    "simulator = Simulator(model_config=model_config)\n",
    "\n",
    "print(\"Simulator initialized successfully!\")"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "metadata": {},
   "source": [
    "## Run Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation for each persona\n",
    "print(\"Running Customer Simulation:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for scenario in simulation_scenarios:\n",
    "    persona = scenario[\"persona\"]\n",
    "    queries = scenario[\"queries\"]\n",
    "    \n",
    "    print(f\"\\nðŸŽ­ Testing {persona}:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    persona_results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nâ“ Query: {query}\")\n",
    "        \n",
    "        # Test the query\n",
    "        result = await query_restaurant_agent_async(query)\n",
    "        persona_results.append(result)\n",
    "        \n",
    "        # Display response\n",
    "        response = result[\"response\"]\n",
    "        if len(response) > 150:\n",
    "            display_response = response[:150] + \"...\"\n",
    "        else:\n",
    "            display_response = response\n",
    "            \n",
    "        print(f\"ðŸ’¬ Response: {display_response}\")\n",
    "    \n",
    "    all_results.append({\n",
    "        \"persona\": persona,\n",
    "        \"results\": persona_results\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ… Simulation completed for {len(simulation_scenarios)} personas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Simulation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the simulation results\n",
    "print(\"Simulation Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_queries = 0\n",
    "successful_responses = 0\n",
    "restaurant_focused_responses = 0\n",
    "\n",
    "for persona_data in all_results:\n",
    "    persona = persona_data[\"persona\"]\n",
    "    results = persona_data[\"results\"]\n",
    "    \n",
    "    print(f\"\\n{persona}:\")\n",
    "    \n",
    "    persona_success = 0\n",
    "    persona_restaurant_focus = 0\n",
    "    \n",
    "    for result in results:\n",
    "        total_queries += 1\n",
    "        response = result[\"response\"].lower()\n",
    "        \n",
    "        # Check if response is successful (not an error)\n",
    "        if not response.startswith(\"error\") and not response.startswith(\"agent run failed\"):\n",
    "            successful_responses += 1\n",
    "            persona_success += 1\n",
    "            \n",
    "            # Check if response mentions restaurant-specific content\n",
    "            if \"scheibmeir\" in response or \"restaurant\" in response or \"menu\" in response:\n",
    "                restaurant_focused_responses += 1\n",
    "                persona_restaurant_focus += 1\n",
    "    \n",
    "    print(f\"  âœ“ Success rate: {(persona_success/len(results))*100:.1f}%\")\n",
    "    print(f\"  ðŸŽ¯ Restaurant focus: {(persona_restaurant_focus/len(results))*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nOverall Simulation Results:\")\n",
    "print(f\"Total queries tested: {total_queries}\")\n",
    "print(f\"Successful responses: {successful_responses}\")\n",
    "print(f\"Overall success rate: {(successful_responses/total_queries)*100:.1f}%\")\n",
    "print(f\"Restaurant-focused responses: {restaurant_focused_responses}\")\n",
    "print(f\"Restaurant focus rate: {(restaurant_focused_responses/total_queries)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ðŸŽ‰ Simulator-based evaluation completed!\")\n",
    "print(\"\\nThis simulation tested how well the agent handles different\")\n",
    "print(\"customer personas and their typical questions about the restaurant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
=======
   "metadata": {},\n",
    "metadata": {},\n",
   "source": [\n",
    "## Generate Simulated Conversations\\n\",\n",
    "\\n\",\n",
    "The simulator will generate realistic restaurant customer queries based on the context we provide.\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    "    \"# Define the context for the simulator\\n\",\n",
    "    \"restaurant_context = \\\"\\\"\\\"\\n\",\n",
    "    \"You are simulating customers interacting with Scheibmeir's Steaks, Snacks and Sticks restaurant assistant.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Restaurant Information:\\n\",\n",
    "    \"- Name: Scheibmeir's Steaks, Snacks and Sticks\\n\",\n",
    "    \"- Location: 340 Jefferson St., San Francisco, CA\\n\",\n",
    "    \"- Founded: 1996 in Fort Collins, Colorado by Chef Jim Scheibmeir\\n\",\n",
    "    \"- Cuisine: Steaks, American appetizers, Chinese-inspired dishes, and Jello salads\\n\",\n",
    "    \"- Hours: Mon-Thu 4-10pm, Fri 4-11pm, Sat 12-11pm, Sun 12-9pm\\n\",\n",
    "    \"- Phone: (415) 555-STEAK\\n\",\n",
    "    \"- Email: info@scheibmeirs.com\\n\",\n",
    "    \"\\n\",\n",
    "    \"Generate diverse customer queries including:\\n\",\n",
    "    \"- Questions about menu items and prices\\n\",\n",
    "    \"- Requests for restaurant information (hours, location, contact)\\n\",\n",
    "    \"- Reservation and dining inquiries\\n\",\n",
    "    \"- Questions about restaurant history and chef\\n\",\n",
    "    \"- Some off-topic questions to test the agent's focus\\n\",\n",
    "    \"\\\"\\\"\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Restaurant context defined for simulator!\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Generate simulated conversations\\n\",\n",
    \"    \"print(\\\"Generating simulated restaurant customer queries...\\\")\\n\",\n",
    \"    \"print(\\\"This may take a few minutes.\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"simulated_conversations = await simulator.generate_async(\\n\",\n",
    \"    \"    target=query_restaurant_agent_async,\\n\",\n",
    \"    \"    text_inputs=[restaurant_context],\\n\",\n",
    \"    \"    num_queries=50,  # Generate 50 simulated queries\\n\",\n",
    \"    \"    max_conversation_turns=1,  # Single turn conversations\\n\",\n",
    \"    \")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(f\\\"Generated {len(simulated_conversations)} simulated conversations!\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"# Save simulated data for evaluation\\n\",\n",
    \"    \"simulated_data = []\\n\",\n",
    \"    \"for i, conversation in enumerate(simulated_conversations):\\n\",\n",
    \"    \"    simulated_data.append({\\n\",\n",
    \"    \"        \\\"query\\\": conversation.get('query', f'Simulated query {i+1}'),\\n\",\n",
    \"    \"        \\\"response\\\": conversation.get('response', 'No response'),\\n\",\n",
    \"    \"        \\\"conversation_id\\\": f\\\"sim_{i+1}\\\"\\n\",\n",
    \"    \"    })\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"# Save to JSONL file\\n\",\n",
    \"    \"with open(\\\"simulated_queries.jsonl\\\", \\\"w\\\") as f:\\n\",\n",
    \"    \"    for item in simulated_data:\\n\",\n",
    \"    \"        f.write(json.dumps(item) + \\\"\\\\n\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"Simulated data saved to simulated_queries.jsonl\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Preview Generated Queries\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Show sample generated queries\\n\",\n",
    \"    \"print(\\\"Sample Generated Queries:\\\")\\n\",\n",
    \"    \"print(\\\"=\\\" * 50)\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"for i in range(min(10, len(simulated_data))):\\n\",\n",
    \"    \"    query = simulated_data[i]['query']\\n\",\n",
    \"    \"    response = simulated_data[i]['response']\\n\",\n",
    \"    \"    print(f\\\"\\\\n{i+1}. Query: {query}\\\")\\n\",\n",
    \"    \"    print(f\\\"   Response: {response[:150]}{'...' if len(response) > 150 else ''}\\\")\\n\",\n",
    \"    \"    print(\\\"-\\\" * 60)\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Configure Evaluators\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Initialize evaluators\\n\",\n",
    \"    \"groundedness_evaluator = GroundednessEvaluator(model_config=model_config)\\n\",\n",
    \"    \"relevance_evaluator = RelevanceEvaluator(model_config=model_config)\\n\",\n",
    \"    \"coherence_evaluator = CoherenceEvaluator(model_config=model_config)\\n\",\n",
    \"    \"fluency_evaluator = FluencyEvaluator(model_config=model_config)\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"Evaluators configured successfully!\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Run Evaluation on Simulated Data\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Azure AI project configuration\\n\",\n",
    \"    \"azure_ai_project = {\\n\",\n",
    \"    \"    \\\"subscription_id\\\": AZURE_SUBSCRIPTION_ID,\\n\",\n",
    \"    \"    \\\"project_name\\\": AZURE_PROJECT_NAME,\\n\",\n",
    \"    \"    \\\"resource_group_name\\\": AZURE_RESOURCE_GROUP_NAME,\\n\",\n",
    \"    \"}\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"# Run evaluation on simulated data\\n\",\n",
    \"    \"print(\\\"Starting evaluation on simulated data...\\\")\\n\",\n",
    \"    \"print(\\\"This may take several minutes.\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"evaluation_result = evaluate(\\n\",\n",
    \"    \"    data=\\\"simulated_queries.jsonl\\\",\\n\",\n",
    \"    \"    target=query_restaurant_agent_async,\\n\",\n",
    \"    \"    evaluators={\\n\",\n",
    \"    \"        \\\"groundedness\\\": groundedness_evaluator,\\n\",\n",
    \"    \"        \\\"relevance\\\": relevance_evaluator,\\n\",\n",
    \"    \"        \\\"coherence\\\": coherence_evaluator,\\n\",\n",
    \"    \"        \\\"fluency\\\": fluency_evaluator,\\n\",\n",
    \"    \"    },\\n\",\n",
    \"    \"    azure_ai_project=azure_ai_project,\\n\",\n",
    \"    \")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"Evaluation completed!\\\")\\n\",\n",
    \"    \"print(f\\\"Azure AI Foundry Studio URL: {evaluation_result.get('studio_url')}\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Display Results\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Display evaluation metrics\\n\",\n",
    \"    \"print(\\\"Simulator-Based Evaluation Metrics:\\\")\\n\",\n",
    \"    \"print(\\\"=\\\" * 50)\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"metrics = evaluation_result.get(\\\"metrics\\\", {})\\n\",\n",
    \"    \"for metric_name, metric_value in metrics.items():\\n\",\n",
    \"    \"    print(f\\\"{metric_name}: {metric_value:.4f}\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"\\\\nDetailed results are available in Azure AI Foundry Studio.\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Alternative: Conversation Starter Simulation\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"Let's also try generating queries using conversation starters specific to restaurant scenarios.\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Define conversation starters for restaurant scenarios\\n\",\n",
    \"    \"conversation_starters = [\\n\",\n",
    \"    \"    \\\"I'm looking for information about your restaurant\\\",\\n\",\n",
    \"    \"    \\\"I'd like to know about your menu\\\",\\n\",\n",
    \"    \"    \\\"What are your operating hours?\\\",\\n\",\n",
    \"    \"    \\\"I want to make a reservation\\\",\\n\",\n",
    \"    \"    \\\"Tell me about your steaks\\\",\\n\",\n",
    \"    \"    \\\"I have dietary restrictions\\\",\\n\",\n",
    \"    \"    \\\"What's the price range for dinner?\\\",\\n\",\n",
    \"    \"    \\\"I'm celebrating a special occasion\\\",\\n\",\n",
    \"    \"    \\\"How do I contact the restaurant?\\\",\\n\",\n",
    \"    \"    \\\"Tell me about the restaurant's history\\\",\\n\",\n",
    \"    \"]\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"Generating queries from conversation starters...\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"# Generate more targeted queries\\n\",\n",
    \"    \"targeted_conversations = await simulator.generate_async(\\n\",\n",
    \"    \"    target=query_restaurant_agent_async,\\n\",\n",
    \"    \"    text_inputs=conversation_starters,\\n\",\n",
    \"    \"    num_queries=30,  # Generate 30 targeted queries\\n\",\n",
    \"    \"    max_conversation_turns=1,\\n\",\n",
    \"    \")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(f\\\"Generated {len(targeted_conversations)} targeted conversations!\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"# Show some examples\\n\",\n",
    \"    \"print(\\\"\\\\nSample Targeted Queries:\\\")\\n\",\n",
    \"    \"print(\\\"-\\\" * 40)\\n\",\n",
    \"    \"for i in range(min(5, len(targeted_conversations))):\\n\",\n",
    \"    \"    conv = targeted_conversations[i]\\n\",\n",
    \"    \"    query = conv.get('query', f'Targeted query {i+1}')\\n\",\n",
    \"    \"    response = conv.get('response', 'No response')\\n\",\n",
    \"    \"    print(f\\\"\\\\n{i+1}. Query: {query}\\\")\\n\",\n",
    \"    \"    print(f\\\"   Response: {response[:150]}{'...' if len(response) > 150 else ''}\\\")\\n\",\n",
    \"    \"    print(\\\"-\\\" * 60)\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Compare Simulation Approaches\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"Let's compare the different approaches to understand their effectiveness.\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"code\",\n",
   \"execution_count\": null,\n",
   \"metadata\": {},\n",
   \"outputs\": [],\n",
   \"source\": [\n",
    \"    \"# Summary of different evaluation approaches\\n\",\n",
    \"    \"print(\\\"Evaluation Approach Comparison:\\\")\\n\",\n",
    \"    \"print(\\\"=\\\" * 50)\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"1. Pre-defined Queries (.jsonl file):\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Predictable and reproducible\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Covers specific test cases\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Good for regression testing\\\")\\n\",\n",
    \"    \"print(\\\"   - Limited diversity\\\")\\n\",\n",
    \"    \"print(\\\"   - Manual creation effort\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"2. AI Simulator (General Context):\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ High diversity of queries\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Discovers edge cases\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Realistic customer language\\\")\\n\",\n",
    \"    \"print(\\\"   - Less predictable\\\")\\n\",\n",
    \"    \"print(\\\"   - May generate irrelevant queries\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"3. AI Simulator (Conversation Starters):\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Balanced approach\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Relevant to specific use cases\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Natural conversation flow\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Good for exploratory testing\\\")\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"print(\\\"4. Red Team Evaluation:\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Tests safety and robustness\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Adversarial attack detection\\\")\\n\",\n",
    \"    \"print(\\\"   âœ“ Compliance and risk assessment\\\")\\n\",\n",
    \"    \"print(\\\"   - Focused on safety, not functionality\\\")\"\n",
   ]\n",
  },\n",
  {\n",
   \"cell_type\": \"markdown\",\n",
   \"metadata\": {},\n",
   \"source\": [\n",
    \"    \"## Summary and Recommendations\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"This simulator-based evaluation notebook demonstrates:\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"### Key Features:\\n\",\n",
    \"    \"1. **AI-Generated Queries**: Uses Azure AI to generate realistic customer queries\\n\",\n",
    \"    \"2. **Context-Aware**: Generates queries relevant to restaurant scenarios\\n\",\n",
    \"    \"3. **Diverse Testing**: Discovers edge cases and unexpected query patterns\\n\",\n",
    \"    \"4. **Natural Language**: Tests with realistic customer language and phrasing\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"### Benefits:\\n\",\n",
    \"    \"- **Scalable**: Can generate hundreds of test queries automatically\\n\",\n",
    \"    \"- **Dynamic**: Each run produces different queries for comprehensive testing\\n\",\n",
    \"    \"- **Realistic**: Simulates actual customer interactions\\n\",\n",
    \"    \"- **Exploratory**: Helps discover unexpected agent behaviors\\n\",\n",
    \"    \"\\n\",\n",
    \"    \"### Best Practices:\\n\",\n",
    \"    \"1. **Combine Approaches**: Use both pre-defined and simulated queries\\n\",\n",
    \"    \"2. **Regular Testing**: Run simulations periodically to catch regressions\\n\",\n",
    \"    \"3. **Context Refinement**: Adjust context based on discovered issues\\n\",\n",
    \"    \"4. **Metric Monitoring**: Track evaluation scores over time\\n\",\n",
    \"    \"5. **Manual Review**: Review generated queries and responses for quality\"\n",
   ]\n",
  }\n",
 ],\n",
 \"metadata\": {\n",
  \"kernelspec\": {\n",
   \"display_name\": \"Python 3\",\n",
   \"language\": \"python\",\n",
   \"name\": \"python3\"\n",
  },\n",
  \"language_info\": {\n",
   \"codemirror_mode\": {\n",
    \"name\": \"ipython\",\n",
    \"version\": 3\n",
   },\n",
   \"file_extension\": \".py\",\n",
   \"mimetype\": \"text/x-python\",\n",
   \"name\": \"python\",\n",
   \"nbconvert_exporter\": \"python\",\n",
   \"pygments_lexer\": \"ipython3\",\n",
   \"version\": \"3.12.11\"\n",
  }\n",
 },\n",
 \"nbformat\": 4,\n",
 \"nbformat_minor\": 4\n",
}"
>>>>>>> a9366a3 (Add comprehensive Azure AI Foundry restaurant agent evaluation suite)
